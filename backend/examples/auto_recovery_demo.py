#!/usr/bin/env python3
"""
è‡ªåŠ¨é‡å¯å’Œæ¢å¤æœºåˆ¶æ¼”ç¤ºè„šæœ¬

å±•ç¤ºæ¨¡å‹è‡ªåŠ¨é‡å¯ã€æ•…éšœæ¢å¤å’ŒçŠ¶æ€æŒä¹…åŒ–çš„å·¥ä½œåŸç†
"""
import asyncio
import logging
import sys
import os
from datetime import datetime, timedelta
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

from backend.app.services.resource_scheduler import PriorityResourceScheduler, RecoveryReason, PreemptionReason
from backend.app.models.schemas import (
    ModelConfig, GPUInfo, ResourceRequirement, ResourceAllocation
)
from backend.app.models.enums import (
    FrameworkType, ModelStatus, GPUVendor, ScheduleResult
)


class AutoRecoveryDemo:
    """è‡ªåŠ¨æ¢å¤æ¼”ç¤ºç±»"""
    
    def __init__(self):
        # ä½¿ç”¨ä¸´æ—¶çŠ¶æ€æ–‡ä»¶
        self.scheduler = PriorityResourceScheduler("demo_scheduler_state.json")
        self.logger = logging.getLogger(__name__)
    
    def create_demo_models(self) -> List[ModelConfig]:
        """åˆ›å»ºæ¼”ç¤ºæ¨¡å‹é…ç½®"""
        return [
            ModelConfig(
                id="critical_service",
                name="å…³é”®æœåŠ¡æ¨¡å‹",
                framework=FrameworkType.VLLM,
                model_path="/models/critical_service.safetensors",
                priority=9,
                gpu_devices=[0],
                parameters={
                    "model_size_gb": 13.0,
                    "precision": "fp16",
                    "max_seq_len": 2048
                },
                resource_requirements=ResourceRequirement(
                    gpu_memory=16384,  # 16GB
                    gpu_devices=[0]
                )
            ),
            ModelConfig(
                id="backup_service",
                name="å¤‡ç”¨æœåŠ¡æ¨¡å‹",
                framework=FrameworkType.LLAMA_CPP,
                model_path="/models/backup_service.gguf",
                priority=7,
                gpu_devices=[1],
                parameters={
                    "model_size_gb": 7.0,
                    "precision": "fp16",
                    "n_ctx": 2048
                },
                resource_requirements=ResourceRequirement(
                    gpu_memory=10240,  # 10GB
                    gpu_devices=[1]
                )
            ),
            ModelConfig(
                id="experimental_service",
                name="å®éªŒæœåŠ¡æ¨¡å‹",
                framework=FrameworkType.LLAMA_CPP,
                model_path="/models/experimental.gguf",
                priority=3,
                gpu_devices=[0],
                parameters={
                    "model_size_gb": 3.0,
                    "precision": "int8",
                    "n_ctx": 1024
                },
                resource_requirements=ResourceRequirement(
                    gpu_memory=4096,  # 4GB
                    gpu_devices=[0]
                )
            )
        ]
    
    def create_demo_gpu_info(self) -> List[GPUInfo]:
        """åˆ›å»ºæ¼”ç¤ºGPUä¿¡æ¯"""
        return [
            GPUInfo(
                device_id=0,
                name="NVIDIA RTX 4090",
                vendor=GPUVendor.NVIDIA,
                memory_total=24576,  # 24GB
                memory_used=0,
                memory_free=24576,
                utilization=0.0,
                temperature=45.0,
                power_usage=50.0
            ),
            GPUInfo(
                device_id=1,
                name="NVIDIA RTX 4090",
                vendor=GPUVendor.NVIDIA,
                memory_total=24576,  # 24GB
                memory_used=0,
                memory_free=24576,
                utilization=0.0,
                temperature=42.0,
                power_usage=45.0
            )
        ]
    
    def print_recovery_stats(self):
        """æ‰“å°æ¢å¤ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.scheduler.get_recovery_stats()
        
        print("\n=== æ¢å¤ç»Ÿè®¡ä¿¡æ¯ ===")
        print(f"æ¢å¤é˜Ÿåˆ—å¤§å°: {stats['recovery_queue_size']}")
        print(f"è¿‡å»1å°æ—¶æ¢å¤å°è¯•: {stats['recovery_attempts_last_hour']}")
        print(f"è¿‡å»24å°æ—¶æ¢å¤å°è¯•: {stats['recovery_attempts_last_day']}")
        print(f"1å°æ—¶æˆåŠŸç‡: {stats['recovery_success_rate_hour']:.2%}")
        print(f"24å°æ—¶æˆåŠŸç‡: {stats['recovery_success_rate_day']:.2%}")
        print(f"è‡ªåŠ¨æ¢å¤å¯ç”¨: {stats['auto_recovery_enabled']}")
        print(f"æ•…éšœæ¢å¤å¯ç”¨: {stats['failure_recovery_enabled']}")
        
        if stats['pending_recovery_models']:
            print(f"å¾…æ¢å¤æ¨¡å‹: {stats['pending_recovery_models']}")
        
        if stats['model_recovery_counts']:
            print("\næ¨¡å‹æ¢å¤ç»Ÿè®¡:")
            for model_id, counts in stats['model_recovery_counts'].items():
                if counts['total'] > 0:
                    success_rate = counts['success'] / counts['total']
                    print(f"  {model_id}: {counts['success']}/{counts['total']} ({success_rate:.2%})")
    
    def print_model_status(self, title: str = "æ¨¡å‹çŠ¶æ€"):
        """æ‰“å°æ¨¡å‹çŠ¶æ€"""
        print(f"\n=== {title} ===")
        model_states = self.scheduler.get_model_states()
        
        for model_id, state in model_states.items():
            status_icon = {
                ModelStatus.STOPPED: "â¹ï¸",
                ModelStatus.STARTING: "ğŸ”„",
                ModelStatus.RUNNING: "âœ…",
                ModelStatus.ERROR: "âŒ",
                ModelStatus.STOPPING: "â¸ï¸",
                ModelStatus.PREEMPTED: "âš ï¸"
            }.get(state.status, "â“")
            
            print(f"{status_icon} {state.config.name}")
            print(f"   çŠ¶æ€: {state.status.value}")
            print(f"   ä¼˜å…ˆçº§: {state.config.priority}")
            if state.allocated_resources:
                print(f"   GPU: {state.allocated_resources.gpu_devices}")
                print(f"   å†…å­˜: {state.allocated_resources.memory_allocated}MB")
            if state.preemption_count > 0:
                print(f"   è¢«æŠ¢å æ¬¡æ•°: {state.preemption_count}")
    
    async def simulate_model_startup(self, model_id: str, gpu_info: List[GPUInfo]):
        """æ¨¡æ‹Ÿæ¨¡å‹å¯åŠ¨"""
        model_state = self.scheduler._model_states.get(model_id)
        if not model_state:
            return
        
        # æ¨¡æ‹Ÿå¯åŠ¨è¿‡ç¨‹
        self.scheduler.update_model_status(model_id, ModelStatus.STARTING)
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¯åŠ¨æ—¶é—´
        
        # åˆ†é…èµ„æº
        model_state.allocated_resources = ResourceAllocation(
            gpu_devices=model_state.config.resource_requirements.gpu_devices,
            memory_allocated=model_state.config.resource_requirements.gpu_memory,
            allocation_time=datetime.now()
        )
        
        # æ›´æ–°GPUçŠ¶æ€
        for gpu_id in model_state.allocated_resources.gpu_devices:
            gpu = next((g for g in gpu_info if g.device_id == gpu_id), None)
            if gpu:
                gpu.memory_used += model_state.allocated_resources.memory_allocated
                gpu.memory_free = gpu.memory_total - gpu.memory_used
                gpu.utilization = min(100.0, (gpu.memory_used / gpu.memory_total) * 100)
        
        self.scheduler.update_model_status(model_id, ModelStatus.RUNNING)
        model_state.last_scheduled = datetime.now()
    
    async def simulate_model_failure(self, model_id: str, gpu_info: List[GPUInfo]):
        """æ¨¡æ‹Ÿæ¨¡å‹æ•…éšœ"""
        model_state = self.scheduler._model_states.get(model_id)
        if not model_state:
            return
        
        print(f"ğŸ’¥ æ¨¡æ‹Ÿæ¨¡å‹ {model_id} å‘ç”Ÿæ•…éšœ")
        
        # é‡Šæ”¾èµ„æº
        if model_state.allocated_resources:
            for gpu_id in model_state.allocated_resources.gpu_devices:
                gpu = next((g for g in gpu_info if g.device_id == gpu_id), None)
                if gpu:
                    gpu.memory_used -= model_state.allocated_resources.memory_allocated
                    gpu.memory_free = gpu.memory_total - gpu.memory_used
                    gpu.utilization = max(0.0, (gpu.memory_used / gpu.memory_total) * 100)
            
            model_state.allocated_resources = None
        
        # è®¾ç½®ä¸ºé”™è¯¯çŠ¶æ€
        self.scheduler.update_model_status(model_id, ModelStatus.ERROR)
        
        # æ·»åŠ åˆ°æ¢å¤é˜Ÿåˆ—
        self.scheduler.add_to_recovery_queue(model_id)
    
    async def mock_gpu_monitor(self, gpu_info: List[GPUInfo]):
        """æ¨¡æ‹ŸGPUç›‘æ§å™¨"""
        return gpu_info
    
    async def mock_resource_calculator(self, config: ModelConfig):
        """æ¨¡æ‹Ÿèµ„æºè®¡ç®—å™¨"""
        return config.resource_requirements
    
    async def mock_resource_validation(self, requirement: ResourceRequirement, gpu_info: List[GPUInfo]):
        """æ¨¡æ‹Ÿèµ„æºéªŒè¯"""
        # ç®€å•æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå†…å­˜
        for gpu_id in requirement.gpu_devices:
            gpu = next((g for g in gpu_info if g.device_id == gpu_id), None)
            if gpu and gpu.memory_free >= requirement.gpu_memory:
                allocation = ResourceAllocation(
                    gpu_devices=[gpu_id],
                    memory_allocated=requirement.gpu_memory,
                    allocation_time=datetime.now()
                )
                return True, [], allocation
        
        return False, ["å†…å­˜ä¸è¶³"], None
    
    async def run_demo(self):
        """è¿è¡Œæ¼”ç¤º"""
        print("ğŸš€ è‡ªåŠ¨é‡å¯å’Œæ¢å¤æœºåˆ¶æ¼”ç¤ºå¼€å§‹")
        print("=" * 60)
        
        # åˆ›å»ºæ¼”ç¤ºæ•°æ®
        models = self.create_demo_models()
        gpu_info = self.create_demo_gpu_info()
        
        # æ³¨å†Œæ¨¡å‹
        print("\nğŸ“ æ³¨å†Œæ¨¡å‹åˆ°è°ƒåº¦å™¨...")
        for model in models:
            self.scheduler.register_model(model)
        
        # è®¾ç½®æ¨¡æ‹Ÿå‡½æ•°
        import backend.app.services.resource_scheduler as scheduler_module
        scheduler_module.gpu_monitor.get_gpu_info = lambda: asyncio.create_task(self.mock_gpu_monitor(gpu_info))
        scheduler_module.resource_calculator.calculate_model_memory_requirement = lambda config: self.mock_resource_calculator(config)
        scheduler_module.resource_calculator.validate_resource_allocation = lambda req, gpus: self.mock_resource_validation(req, gpu_info)
        
        self.print_model_status("åˆå§‹æ¨¡å‹çŠ¶æ€")
        
        # åœºæ™¯1: å¯åŠ¨æ¨¡å‹æœåŠ¡
        print("\n" + "=" * 60)
        print("ğŸ“‹ åœºæ™¯1: å¯åŠ¨æ¨¡å‹æœåŠ¡")
        print("=" * 60)
        
        for model_id in ["critical_service", "backup_service", "experimental_service"]:
            print(f"\nğŸ”„ å¯åŠ¨æ¨¡å‹: {model_id}")
            await self.simulate_model_startup(model_id, gpu_info)
        
        self.print_model_status("å¯åŠ¨åæ¨¡å‹çŠ¶æ€")
        
        # åœºæ™¯2: æ¨¡æ‹Ÿæ•…éšœå’Œè‡ªåŠ¨æ¢å¤
        print("\n" + "=" * 60)
        print("ğŸ“‹ åœºæ™¯2: æ¨¡æ‹Ÿæ•…éšœå’Œè‡ªåŠ¨æ¢å¤")
        print("=" * 60)
        
        # æ¨¡æ‹Ÿå®éªŒæœåŠ¡æ•…éšœ
        await self.simulate_model_failure("experimental_service", gpu_info)
        
        self.print_model_status("æ•…éšœåæ¨¡å‹çŠ¶æ€")
        self.print_recovery_stats()
        
        # å°è¯•è‡ªåŠ¨æ¢å¤
        print("\nğŸ”„ å°è¯•è‡ªåŠ¨æ¢å¤æ•…éšœæ¨¡å‹...")
        result = await self.scheduler._attempt_model_recovery(
            "experimental_service", 
            RecoveryReason.FAILURE_RECOVERY
        )
        
        if result:
            print("âœ… è‡ªåŠ¨æ¢å¤æˆåŠŸ")
            await self.simulate_model_startup("experimental_service", gpu_info)
        else:
            print("âŒ è‡ªåŠ¨æ¢å¤å¤±è´¥")
        
        self.print_model_status("æ¢å¤åæ¨¡å‹çŠ¶æ€")
        
        # åœºæ™¯3: æ‰‹åŠ¨é‡å¯æ¨¡å‹
        print("\n" + "=" * 60)
        print("ğŸ“‹ åœºæ™¯3: æ‰‹åŠ¨é‡å¯æ¨¡å‹")
        print("=" * 60)
        
        print("ğŸ”„ æ‰‹åŠ¨é‡å¯å…³é”®æœåŠ¡æ¨¡å‹...")
        
        # å…ˆåœæ­¢æ¨¡å‹
        await self.simulate_model_failure("critical_service", gpu_info)
        
        # æ‰‹åŠ¨é‡å¯
        restart_result = await self.scheduler.restart_model("critical_service")
        
        if restart_result:
            print("âœ… æ‰‹åŠ¨é‡å¯æˆåŠŸ")
            await self.simulate_model_startup("critical_service", gpu_info)
        else:
            print("âŒ æ‰‹åŠ¨é‡å¯å¤±è´¥")
        
        self.print_model_status("é‡å¯åæ¨¡å‹çŠ¶æ€")
        
        # åœºæ™¯4: æŠ¢å å’Œæ¢å¤
        print("\n" + "=" * 60)
        print("ğŸ“‹ åœºæ™¯4: æŠ¢å å’Œæ¢å¤æœºåˆ¶")
        print("=" * 60)
        
        # æ¨¡æ‹Ÿé«˜ä¼˜å…ˆçº§æ¨¡å‹éœ€è¦èµ„æº
        print("ğŸ”¥ é«˜ä¼˜å…ˆçº§æ¨¡å‹è¯·æ±‚èµ„æºï¼Œè§¦å‘æŠ¢å ...")
        
        # æ‰‹åŠ¨æŠ¢å ä½ä¼˜å…ˆçº§æ¨¡å‹
        await self.scheduler._preempt_model("experimental_service", PreemptionReason.HIGHER_PRIORITY)
        
        # é‡Šæ”¾èµ„æº
        model_state = self.scheduler._model_states["experimental_service"]
        if model_state.allocated_resources:
            for gpu_id in model_state.allocated_resources.gpu_devices:
                gpu = next((g for g in gpu_info if g.device_id == gpu_id), None)
                if gpu:
                    gpu.memory_used -= model_state.allocated_resources.memory_allocated
                    gpu.memory_free = gpu.memory_total - gpu.memory_used
                    gpu.utilization = max(0.0, (gpu.memory_used / gpu.memory_total) * 100)
        
        self.print_model_status("æŠ¢å åæ¨¡å‹çŠ¶æ€")
        
        # å°è¯•æ¢å¤è¢«æŠ¢å çš„æ¨¡å‹
        print("\nğŸ”„ å°è¯•æ¢å¤è¢«æŠ¢å çš„æ¨¡å‹...")
        recovery_result = await self.scheduler.manual_recover_model("experimental_service")
        
        if recovery_result:
            print("âœ… æ¢å¤æˆåŠŸ")
            await self.simulate_model_startup("experimental_service", gpu_info)
        else:
            print("âŒ æ¢å¤å¤±è´¥ï¼Œèµ„æºä¸è¶³")
        
        self.print_model_status("æœ€ç»ˆæ¨¡å‹çŠ¶æ€")
        
        # åœºæ™¯5: çŠ¶æ€æŒä¹…åŒ–æ¼”ç¤º
        print("\n" + "=" * 60)
        print("ğŸ“‹ åœºæ™¯5: çŠ¶æ€æŒä¹…åŒ–")
        print("=" * 60)
        
        print("ğŸ’¾ ä¿å­˜è°ƒåº¦å™¨çŠ¶æ€...")
        self.scheduler._save_state()
        
        print("ğŸ“Š å½“å‰æ¢å¤é˜Ÿåˆ—:")
        recovery_queue = self.scheduler.get_recovery_queue()
        if recovery_queue:
            for model_id in recovery_queue:
                model_name = self.scheduler._model_states[model_id].config.name
                print(f"  - {model_name} ({model_id})")
        else:
            print("  æ¢å¤é˜Ÿåˆ—ä¸ºç©º")
        
        # æœ€ç»ˆç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡")
        print("=" * 60)
        
        self.print_recovery_stats()
        
        # æ˜¾ç¤ºè°ƒåº¦å†å²
        print("\n=== è°ƒåº¦å†å² ===")
        history = self.scheduler.get_schedule_history(5)
        for i, decision in enumerate(reversed(history), 1):
            print(f"{i}. æ¨¡å‹: {decision.model_id}")
            print(f"   æ—¶é—´: {decision.decision_time.strftime('%H:%M:%S')}")
            print(f"   ç»“æœ: {decision.result.value}")
            print(f"   åŸå› : {decision.reason}")
        
        print("\n" + "=" * 60)
        print("âœ… æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)
        
        # æ¸…ç†
        await self.scheduler.shutdown()
        
        # åˆ é™¤æ¼”ç¤ºçŠ¶æ€æ–‡ä»¶
        try:
            os.remove("demo_scheduler_state.json")
        except:
            pass


async def main():
    """ä¸»å‡½æ•°"""
    demo = AutoRecoveryDemo()
    await demo.run_demo()


if __name__ == "__main__":
    asyncio.run(main())